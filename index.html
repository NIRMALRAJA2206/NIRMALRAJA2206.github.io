<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Nirmal Raja Loganathan | Portfolio</title>
    <meta
      name="description"
      content="PhD Robotics Researcher focused on perception, manipulation, and motion planning."
    />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Manrope:wght@400;500;700;800&family=IBM+Plex+Mono:wght@400;500&display=swap"
      rel="stylesheet"
    />
    <link rel="stylesheet" href="styles.css" />
  </head>
  <body>
    <div class="noise" aria-hidden="true"></div>

    <header class="topbar">
      <div class="topbar-inner">
        <a class="logo" href="#about">Nirmal Raja</a>
        <nav class="menu" aria-label="Main navigation">
          <a href="#about">About</a>
          <a href="#publications">Publications</a>
          <a href="#projects">Projects</a>
        </nav>
      </div>
    </header>

    <main class="container">
      <section id="about" class="panel hero reveal">
        <p class="eyebrow">NIRMAL RAJA LOGANATHAN</p>
        <h1>PhD Robotics Researcher building real-world autonomy systems from perception to planning.</h1>
        <p class="summary">
          I develop production-oriented robotics AI systems for manipulation, autonomous driving,
          and field robotics. My work combines stereo vision, deep learning, and motion planning
          to deliver robust behavior under real-world noise, uncertainty, and latency constraints.
          I am currently seeking Summer 2026 internships (CPT eligible).
        </p>

        <div class="socials" aria-label="Social links">
          <a class="chip" href="https://linkedin.com/in/nl2206" target="_blank" rel="noreferrer">LinkedIn</a>
          <a class="chip" href="https://scholar.google.com/citations?user=lCGSU10AAAAJ&hl=en" target="_blank" rel="noreferrer">Google Scholar</a>
          <a class="chip" href="https://github.com/NIRMALRAJA2206" target="_blank" rel="noreferrer">GitHub</a>
          <a class="chip" href="mailto:karuppia@mtu.edu">Email</a>
          <a class="chip" href="nirmal_resume.pdf" target="_blank" rel="noreferrer">Resume</a>
        </div>

        <div class="about-grid">
          <article class="mini-card">
            <h3>Current Research</h3>
            <p>Multi-robot asynchronous planning and vision-guided cooperative assembly with dual-arm UR5e, ROS 2, MoveIt2, and stereo + YOLO pipelines.</p>
          </article>
          <article class="mini-card">
            <h3>Core Strengths</h3>
            <p>Computer vision, robotic manipulation, stereo calibration, trajectory planning, CUDA optimization, and sim-to-real transfer.</p>
          </article>
          <article class="mini-card">
            <h3>Education</h3>
            <p>PhD (Computational Science & Engineering), MS (Data Science), Michigan Technological University.</p>
          </article>
        </div>

        <p class="meta">Houghton, Michigan · +1 (906) 319-1390 · karuppia@mtu.edu</p>
      </section>

      <section id="publications" class="panel reveal">
        <div class="section-head">
          <h2>Publications</h2>
        </div>
        <ul class="links-list">
          <li>
            <a href="https://saemobilus.sae.org/papers/machine-learning-based-lane-detection-lateral-offset-estimation-model-vehicle-following-applications-2025-01-8020" target="_blank" rel="noreferrer">
              Loganathan, Nirmal Raja Karuppiah, et al. Machine Learning-Based Lane Detection and Lateral Offset Estimation Model for Vehicle Following Applications. SAE Technical Paper, 2025.
            </a>
          </li>
          <li>
            <a href="https://ieeexplore.ieee.org/abstract/document/10307980" target="_blank" rel="noreferrer">
              Priya, E., C. N. Savithri, and Nirmal Raja KL. A machine learning approach to control a Prosthetic arm via signals from residual limb. IEEE ICCCNT, 2023.
            </a>
          </li>
          <li>
            <a href="https://ieeexplore.ieee.org/abstract/document/10170570" target="_blank" rel="noreferrer">
              Gopalram, S., Nirmal Raja KL et al. Smart valve control system for LPG cylinders using IoT. IEEE IConSCEPT, 2023.
            </a>
          </li>
          <li>
            <a href="https://link.springer.com/chapter/10.1007/978-981-16-2641-8_54" target="_blank" rel="noreferrer">
              Prathibha, S., Nirmal Raja K. L., et al. COVID-19 Safe Guard: A Smart Mobile Application to Address Corona Pandemic. Springer, 2021.
            </a>
          </li>
          <li>
            <a href="https://ieeexplore.ieee.org/abstract/document/9673624" target="_blank" rel="noreferrer">
              Ramesh, Reshmaja K., KL Nirmal Raja, et al. Baridefendo - An Autonomous Safety Ensuring System. IEEE ICMSS, 2021.
            </a>
          </li>
          <li>
            <a href="https://ieeexplore.ieee.org/abstract/document/9711816" target="_blank" rel="noreferrer">
              Prathibha, Soma, et al. Navigating Alert for Visually Impaired Using Computer Vision Aided System. IEEE ICCCT, 2021.
            </a>
          </li>
        </ul>
      </section>

      <section id="projects" class="panel reveal">
        <div class="section-head">
          <h2>Projects</h2>
          <a class="inline-link" href="https://github.com/NIRMALRAJA2206" target="_blank" rel="noreferrer">View all on GitHub</a>
        </div>

        <div class="cards featured">
          <article class="card">
            <p class="card-title">Multi-Robot Cooperative Assembly</p>
            <p class="card-meta">ROS 2 · MoveIt2 · Stereo Vision · YOLO</p>
            <p>Dual-arm UR5e assembly workcell with force-aware manipulation skills for approach, grasp, align, insert, and seat operations with recovery behaviors.</p>
          </article>

          <article class="card">
            <p class="card-title">ARPA-E NextCar Autonomous Perception</p>
            <p class="card-meta">YOLOv8 · CLIP · CUDA · AGX Orin</p>
            <p>Lane and stop-line perception stack for vehicle following and autonomous braking, including cm-level lateral offset calibration and 30 FPS deployment.</p>
          </article>

          <article class="card">
            <p class="card-title">Ad Astra Mars Rover</p>
            <p class="card-meta">Stereo SLAM · Hybrid A* · MPC · DBSCAN</p>
            <p>Autonomous rover stack for terrain-aware navigation, astronaut detection, and long-range mission reliability in unstructured environments.</p>
          </article>

          <article class="card">
            <p class="card-title">Nighttime Pedestrian 3D Detection</p>
            <p class="card-meta">Thermal + RGB + Stereo · YOLO</p>
            <p>Multi-sensor fusion pipeline with 3D frustum association for real-time pedestrian distance estimation under low-light and glare conditions.</p>
          </article>

          <article class="card">
            <p class="card-title">Jarvis Vision Flood Rescue Drone</p>
            <p class="card-meta">YOLOv5 · RGB-D · ArUco · CUDA</p>
            <p>Drone perception for person detection, flood-depth estimation, and precision marker-based landing with robust low-latency operation.</p>
          </article>

          <article class="card">
            <p class="card-title">Spot Robot Intent & Collision Avoidance</p>
            <p class="card-meta">Detectron2 · MediaPipe · LiDAR</p>
            <p>Human intent prediction and collision avoidance on Boston Dynamics Spot with real-time inference and cm-level distance calibration.</p>
          </article>
        </div>

        <h3 class="subhead">Latest GitHub Repositories</h3>
        <div id="repo-grid" class="cards cards-repos" aria-live="polite"></div>
      </section>
    </main>

    <script src="script.js"></script>
  </body>
</html>
