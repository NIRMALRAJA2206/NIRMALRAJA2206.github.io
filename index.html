<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Nirmal Raja Loganathan | Portfolio</title>
    <meta
      name="description"
      content="PhD Robotics Researcher focused on perception, manipulation, and motion planning."
    />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Manrope:wght@400;500;700;800&family=IBM+Plex+Mono:wght@400;500&display=swap"
      rel="stylesheet"
    />
    <link rel="stylesheet" href="styles.css?v=2" />
  </head>
  <body>
    <div class="noise" aria-hidden="true"></div>

    <header class="topbar">
      <div class="topbar-inner">
        <a class="logo" href="#about">Nirmal Raja</a>
        <nav class="menu" aria-label="Main navigation">
          <a href="#about">About</a>
          <a href="#publications">Publications</a>
          <a href="#projects">Projects</a>
        </nav>
      </div>
    </header>

    <main class="container">
      <section id="about" class="panel hero reveal">
        <p class="eyebrow">NIRMAL RAJA LOGANATHAN</p>
        <h1>PhD Robotics Researcher building real-world autonomy systems from perception to planning.</h1>
        <p class="summary">
          I develop production-oriented robotics AI systems for manipulation, autonomous driving,
          and field robotics. My work combines stereo vision, deep learning, and motion planning
          to deliver robust behavior under real-world noise, uncertainty, and latency constraints.
          I am currently seeking Summer 2026 internships (CPT eligible).
        </p>

        <div class="socials" aria-label="Social links">
          <a class="social-icon" href="https://linkedin.com/in/nl2206" target="_blank" rel="noreferrer" aria-label="LinkedIn">
            <svg viewBox="0 0 24 24" aria-hidden="true">
              <path d="M6.98 8.5v8.52H4.16V8.5h2.82Zm.2-2.63a1.64 1.64 0 1 1-3.29 0 1.64 1.64 0 0 1 3.29 0ZM19.84 12.15v4.87h-2.81v-4.54c0-1.14-.41-1.92-1.42-1.92-.77 0-1.23.52-1.43 1.02-.08.18-.1.44-.1.69v4.75h-2.82s.04-7.7 0-8.52h2.82v1.21c.37-.58 1.05-1.4 2.55-1.4 1.86 0 3.25 1.21 3.25 3.84Z"/>
            </svg>
            <span class="icon-label">LinkedIn</span>
          </a>
          <a class="social-icon" href="https://scholar.google.com/citations?user=lCGSU10AAAAJ&hl=en" target="_blank" rel="noreferrer" aria-label="Google Scholar">
            <svg viewBox="0 0 24 24" aria-hidden="true">
              <path d="M12 3 2 8l10 5 8.2-4.1V15H22V8L12 3Zm-6.5 9.42V16c0 2.1 3.02 3.8 6.5 3.8s6.5-1.7 6.5-3.8v-3.58L12 16l-6.5-3.58Z"/>
            </svg>
            <span class="icon-label">Google Scholar</span>
          </a>
          <a class="social-icon" href="https://github.com/NIRMALRAJA2206" target="_blank" rel="noreferrer" aria-label="GitHub">
            <svg viewBox="0 0 24 24" aria-hidden="true">
              <path d="M12 2C6.48 2 2 6.6 2 12.27c0 4.53 2.87 8.37 6.84 9.72.5.1.68-.22.68-.49 0-.24-.01-.88-.01-1.73-2.78.62-3.37-1.38-3.37-1.38-.45-1.19-1.11-1.5-1.11-1.5-.9-.64.07-.63.07-.63 1 .08 1.53 1.05 1.53 1.05.88 1.56 2.32 1.11 2.88.85.09-.66.35-1.11.63-1.37-2.22-.26-4.56-1.14-4.56-5.08 0-1.12.39-2.03 1.03-2.75-.1-.26-.45-1.31.1-2.73 0 0 .84-.28 2.75 1.05a9.3 9.3 0 0 1 5 0c1.91-1.33 2.75-1.05 2.75-1.05.55 1.42.2 2.47.1 2.73.64.72 1.03 1.63 1.03 2.75 0 3.95-2.34 4.81-4.57 5.06.36.32.68.95.68 1.92 0 1.39-.01 2.5-.01 2.84 0 .27.18.59.69.49A10.25 10.25 0 0 0 22 12.27C22 6.6 17.52 2 12 2Z"/>
            </svg>
            <span class="icon-label">GitHub</span>
          </a>
          <a class="social-icon" href="mailto:karuppia@mtu.edu" aria-label="Email">
            <svg viewBox="0 0 24 24" aria-hidden="true">
              <path d="M3 6h18a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V7a1 1 0 0 1 1-1Zm0 2v.21l9 5.4 9-5.4V8l-9 5.4L3 8Z"/>
            </svg>
            <span class="icon-label">Email</span>
          </a>
          <a class="social-icon" href="nirmal_resume.pdf" target="_blank" rel="noreferrer" aria-label="Resume">
            <svg viewBox="0 0 24 24" aria-hidden="true">
              <path d="M6 2h8l4 4v16H6a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2Zm7 1.5V7h3.5L13 3.5ZM8 11h8v1.5H8V11Zm0 3.5h8V16H8v-1.5Z"/>
            </svg>
            <span class="icon-label">Resume</span>
          </a>
        </div>

        <div class="about-grid">
          <article class="mini-card">
            <h3>Current Research</h3>
            <p>Multi-robot asynchronous planning and vision-guided cooperative assembly with dual-arm UR5e, ROS 2, MoveIt2, and stereo + YOLO pipelines.</p>
          </article>
          <article class="mini-card">
            <h3>Core Strengths</h3>
            <p>Computer vision, robotic manipulation, stereo calibration, trajectory planning, CUDA optimization, and sim-to-real transfer.</p>
          </article>
          <article class="mini-card">
            <h3>Education</h3>
            <div class="edu-list">
              <div class="edu-item">
                <div>
                  <p class="edu-degree">Ph.D. in Computational Science & Engineering</p>
                  <p class="edu-school">Michigan Technological University</p>
                </div>
                <p class="edu-date">Fall 2025 - Fall 2028</p>
              </div>
              <div class="edu-item">
                <div>
                  <p class="edu-degree">M.S. in Data Science</p>
                  <p class="edu-school">Michigan Technological University</p>
                </div>
                <p class="edu-date">Fall 2023 - Spring 2025</p>
              </div>
              <div class="edu-item">
                <div>
                  <p class="edu-degree">B.E. in Electronics & Communication Engineering</p>
                  <p class="edu-school">Anna University</p>
                </div>
                <p class="edu-date">Fall 2019 - Spring 2023</p>
              </div>
            </div>
          </article>
        </div>

        <p class="meta">Houghton, Michigan · +1 (906) 319-1390 · karuppia@mtu.edu</p>
      </section>

      <section id="publications" class="panel reveal">
        <div class="section-head">
          <h2>Publications</h2>
        </div>
        <ul class="links-list">
          <li>
            <a href="https://saemobilus.sae.org/papers/machine-learning-based-lane-detection-lateral-offset-estimation-model-vehicle-following-applications-2025-01-8020" target="_blank" rel="noreferrer">
              Loganathan, Nirmal Raja Karuppiah, et al. Machine Learning-Based Lane Detection and Lateral Offset Estimation Model for Vehicle Following Applications. SAE Technical Paper, 2025.
            </a>
          </li>
          <li>
            <a href="https://ieeexplore.ieee.org/abstract/document/10307980" target="_blank" rel="noreferrer">
              Priya, E., C. N. Savithri, and Nirmal Raja KL. A machine learning approach to control a Prosthetic arm via signals from residual limb. IEEE ICCCNT, 2023.
            </a>
          </li>
          <li>
            <a href="https://ieeexplore.ieee.org/abstract/document/10170570" target="_blank" rel="noreferrer">
              Gopalram, S., Nirmal Raja KL et al. Smart valve control system for LPG cylinders using IoT. IEEE IConSCEPT, 2023.
            </a>
          </li>
          <li>
            <a href="https://link.springer.com/chapter/10.1007/978-981-16-2641-8_54" target="_blank" rel="noreferrer">
              Prathibha, S., Nirmal Raja K. L., et al. COVID-19 Safe Guard: A Smart Mobile Application to Address Corona Pandemic. Springer, 2021.
            </a>
          </li>
          <li>
            <a href="https://ieeexplore.ieee.org/abstract/document/9673624" target="_blank" rel="noreferrer">
              Ramesh, Reshmaja K., KL Nirmal Raja, et al. Baridefendo - An Autonomous Safety Ensuring System. IEEE ICMSS, 2021.
            </a>
          </li>
          <li>
            <a href="https://ieeexplore.ieee.org/abstract/document/9711816" target="_blank" rel="noreferrer">
              Prathibha, Soma, et al. Navigating Alert for Visually Impaired Using Computer Vision Aided System. IEEE ICCCT, 2021.
            </a>
          </li>
        </ul>
      </section>

      <section id="projects" class="panel reveal">
        <div class="section-head">
          <h2>Projects</h2>
        </div>

        <div class="project-list">
          <article class="project-block">
            <h3>Multi-Robot Asynchronous Planning & Vision for Cooperative Assembly</h3>
            <p class="card-meta">Doctoral Research · July 2025 - Present</p>
            <ul class="detail-list">
              <li>Developing a dual-arm UR5e workcell for precision assembly of electronic components and PCB subassemblies.</li>
              <li>Integrated Robotiq 2F-85 grippers and a custom force-sensing end-effector for press-fit, alignment, and seating tasks.</li>
              <li>Built a ROS 2 Humble + MoveIt2 stack for collision-aware planning, synchronized dual-arm control, and on-robot execution.</li>
              <li>Implemented stereo vision + YOLO detection and instance segmentation for small-part localization to drive pick-and-place and insertion.</li>
              <li>Calibrated stereo-to-robot extrinsics and maintained tf2 transforms for repeatable vision-to-robot alignment.</li>
              <li>Developed manipulation skills (approach, grasp, align, insert, seat) with recovery for pose and contact disturbances.</li>
              <li>Investigating RLPD from demonstrations and sim-to-real transfer robust to perception noise, calibration drift, and contact dynamics.</li>
            </ul>
          </article>

          <article class="project-block">
            <h3>Nighttime Pedestrian Detection with Thermal + Stereo Fusion</h3>
            <p class="card-meta">Automation in Manufacturing and Industrial Systems Lab · Apr 2025 - Aug 2025</p>
            <ul class="detail-list">
              <li>Built a multi-sensor stack (FLIR ADK thermal, RealSense stereo, RGB) for no-light nighttime pedestrian detection under headlight glare and reduced visibility.</li>
              <li>Trained and deployed YOLO thermal detectors for pedestrians and nearby roadway objects when visible-light cameras degrade.</li>
              <li>Fused thermal detections with RealSense stereo depth via 3D frustum association for real-time tracking (~25 FPS) with under 5% error up to 40+ meters.</li>
              <li>Improved thermal stereo calibration using CLAHE and morphological filtering, boosting successful runs by 80%+.</li>
            </ul>
          </article>

          <article class="project-block">
            <h3>ARPA-E NextCar Autonomous Vehicle Perception</h3>
            <p class="card-meta">Advanced Power Systems Research Center · Oct 2023 - Aug 2025</p>
            <ul class="detail-list">
              <li>Led perception design for Level 4/5 autonomy focusing on lateral offset and stop-line estimation for vehicle following and autonomous braking.</li>
              <li>Trained a lane detection pipeline using YOLOv8 on 5k+ images, achieving 82% accuracy on unmarked roads.</li>
              <li>Applied CLIP-based VLM for edge-case labeling, doubling annotation throughput and raising long-tail recall by 11%.</li>
              <li>Designed a 9-point calibration algorithm for cm-level lateral offset estimation (avg. error 0.166 m), validated with GPS RTK and HD maps.</li>
              <li>Optimized inference to 30 FPS on NVIDIA AGX Orin, reducing latency by 32% via CUDA parallelization.</li>
              <li>Developed a stop-line detection model combining traffic signal recognition (8k+ images) and stereo disparity, triggering braking 1.2 m earlier at 92% precision.</li>
              <li>Established GitLab CI/CD and Docker pipelines for automated testing and deployment.</li>
            </ul>
          </article>

          <article class="project-block">
            <h3>Ad Astra Autonomous Rover for Mars Exploration</h3>
            <p class="card-meta">Sairam Techno Incubator Foundation · Mar 2021 - Aug 2023</p>
            <ul class="detail-list">
              <li>Developed autonomy software supporting safe navigation, astronaut detection, and reliable rover operation in unstructured outdoor terrain.</li>
              <li>Implemented stereo SLAM and state-estimation pipeline, achieving ~4 cm RMS pose error and autonomous traverses up to 2 km.</li>
              <li>Designed terrain classification using DBSCAN on stereo point clouds (~14 Hz), achieving 82% F1 while maintaining 0.25 m/s traversal speed.</li>
              <li>Trained Faster R-CNN (ResNet-101, 6k images) for astronaut detection, reaching 87 mAP@0.5 (37% improvement over baseline).</li>
              <li>Integrated CUDA-accelerated Hybrid A* with MPC control, cutting replanning latency from ~450 ms to ~50 ms and reducing curvature error by 42%.</li>
              <li>Led perception, navigation, and safety integration to sustain over 90% mission uptime while resolving 50+ field issues.</li>
            </ul>
          </article>

          <article class="project-block">
            <h3>Jarvis Vision Autonomous Drone for Flood Rescue</h3>
            <p class="card-meta">Sairam Techno Incubator Foundation · 2021 - 2023</p>
            <ul class="detail-list">
              <li>Built a YOLOv5-based person detector with 2D tracking and RGB-D based 3D localization on 90k+ drone frames.</li>
              <li>Estimated flood-water depth using altitude metadata + stereo disparity, evaluated with cm-level RMSE at ~20 FPS.</li>
              <li>Developed a multi-scale encoder-decoder network for single-image 3D building detection and coarse shape reconstruction.</li>
              <li>Integrated ArUco marker pose estimation for precision landing with repeatable centimeter-level touchdown accuracy.</li>
              <li>CUDA-accelerated ROS 2 perception (preprocessing + inference) to reduce latency and maintain performance.</li>
            </ul>
          </article>

          <article class="project-block">
            <h3>Azure Traffic Intelligence Platform</h3>
            <p class="card-meta">Microsoft Future Ready Talent Intern · Sep 2021 - Apr 2022</p>
            <ul class="detail-list">
              <li>Built real-time vehicle detection and clustering using Azure Computer Vision API and enhanced DBSCAN for lane-specific traffic density.</li>
              <li>Designed scalable workflows with Azure Functions and Cosmos DB for real-time ingestion and visualization.</li>
              <li>Integrated detection outputs into live dashboards for dynamic routing and traffic optimization.</li>
            </ul>
          </article>

          <article class="project-block">
            <h3>Human Walking Intent Prediction & Collision Avoidance for Spot</h3>
            <p class="card-meta">Other Projects · Fall 2024</p>
            <ul class="detail-list">
              <li>Built a real-time collision avoidance system using Detectron2 and MediaPipe, achieving 88% accuracy.</li>
              <li>Designed an 8-point calibration system for cm-level distance estimation and deployed on Spot CORE I/O at 30 FPS with LiDAR + stereo integration.</li>
            </ul>
          </article>

          <article class="project-block">
            <h3>Unmasking Deepfakes with DFD50</h3>
            <p class="card-meta">Other Projects · Spring 2024</p>
            <ul class="detail-list">
              <li>Developed a hybrid ResNeXt-50 + LSTM model for deepfake detection, achieving 97% accuracy on DFDC and FF++ datasets.</li>
              <li>Optimized training with AdamW, StepLR, and augmentation, reducing loss from 0.67 to 0.10 and outperforming XceptionNet (F1: 96.24%).</li>
            </ul>
          </article>

          <article class="project-block">
            <h3>AI-Powered Rubber Duck Code Debugging Chatbot</h3>
            <p class="card-meta">Other Projects · Fall 2023</p>
            <ul class="detail-list">
              <li>Built a GPT-4 + CodeBERT debugging bot with AST error flagging, reducing Python debug time by 40% and improving throughput by 15%.</li>
              <li>Deployed a LangChain microservice on AWS EKS with autoscaling for 50+ concurrent users.</li>
            </ul>
          </article>
        </div>
      </section>
    </main>
  </body>
</html>
